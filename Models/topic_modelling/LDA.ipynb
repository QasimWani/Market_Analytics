{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Running LDA analysis on summarized (condensed) text generated from articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(1729)\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_TEXT = ['\\nFrench startup BlaBlaCar has announced that the company’s revenue grew by 71 percent in 2019 compared to 2018',\n",
    " 'Ouibus is now called BlaBlaBus',\n",
    " 'The big difference between 2019 and 2018 is that BlaBlaCar diversified its activity by offering bus rides as well as bus ticketing in some markets.\\nBlaBlaCar is still mostly known for its long-distance ride-sharing marketplace',\n",
    " 'On the other side of the marketplace, if you plan on driving across the country, you can list your ride on the platform to find passengers so that you don’t have to pay for gas and highway tolls by yourself.\\nIn November 2018, the company acquired Ouibus to become a marketplace for road travel, whether it’s by bus or by car',\n",
    " 'If you’re going from one city to another, you can find a car with an empty seat and book a ride in that car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_text(ORIGINAL_TEXT):\n",
    "    \"\"\"Polishes text\"\"\"\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "    STOPWORDS.add(\"-\")\n",
    "    STOPWORDS.add(\"like\")\n",
    "    STOPWORDS.add(\"said\")\n",
    "    STOPWORDS.add(\"forward\")\n",
    "    STOPWORDS.add(\"time\")\n",
    "    frp = []\n",
    "    for i, c in enumerate(ORIGINAL_TEXT):\n",
    "        reg = c.lower()\n",
    "        reg = ' '.join(reg)\n",
    "        reg = ' '.join([word for word in c.split() if word not in STOPWORDS])\n",
    "        reg = re.sub('[^a-zA-Z]', ' ', reg)\n",
    "        reg = re.sub(r'\\s+', ' ', reg)\n",
    "        frp.append(reg)\n",
    "    return frp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLISHED_TEXT = pre_process_text(ORIGINAL_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['French startup BlaBlaCar announced company s revenue grew percent compared ',\n",
       " 'Ouibus called BlaBlaBus',\n",
       " 'The big difference BlaBlaCar diversified activity offering bus rides well bus ticketing markets BlaBlaCar still mostly known long distance ride sharing marketplace',\n",
       " 'On side marketplace plan driving across country list ride platform find passengers don t pay gas highway tolls yourself In November company acquired Ouibus become marketplace road travel whether it s bus car',\n",
       " 'If you re going one city another find car empty seat book ride car']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POLISHED_TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Incorporating stemming instead of lemmatization because of performance and speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(token)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmantized = list(pd.Series(POLISHED_TEXT).map(preprocess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(lemmantized)\n",
    "dictionary.filter_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_frequencies(sentence):\n",
    "    \"\"\"\n",
    "    Generates Frequencies and Occurances of words from a sentence:\n",
    "    1. Parameters : sentence (lemmantized version of the sentence, in list type).\n",
    "    2. Returns : \n",
    "        A. TDM (pandas Series object)\n",
    "        B. DataFrame (pandas TDM representation)\n",
    "    \"\"\"\n",
    "    occurance = {}\n",
    "    frequency = {}\n",
    "    for i, word in enumerate(sentence):\n",
    "        if word not in frequency.keys():\n",
    "            frequency[word] = 1\n",
    "        else:\n",
    "            frequency[word] += 1\n",
    "    max_word_frequency = max(frequency.values())\n",
    "    for word in frequency.keys():\n",
    "        occurance[word] = frequency[word] / max_word_frequency\n",
    "    df = pd.DataFrame(data=[list(frequency.keys()), list(frequency.values()), list(occurance.values())]).T\n",
    "    df.columns = ['Word', 'Occurance', 'Frequency']\n",
    "    return df, frequency, occurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tf_idf(paragraph):\n",
    "    tf_idf = []\n",
    "    for i, lem in enumerate(paragraph):\n",
    "        pd_df, frequency_words, occurance_words = generate_frequencies(lem)\n",
    "        temp = []\n",
    "        for occur, freq in zip(frequency_words.values(), occurance_words.values()):\n",
    "            temp.append(freq * np.log10(len(ORIGINAL_TEXT)/occur))\n",
    "        tf_idf.append(temp)\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TD-IDF generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf_idf = generate_tf_idf(lemmantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "common_dictionary = Dictionary(common_texts)\n",
    "lemmy_BOW = [dictionary.doc2bow(text) for text in lemmantized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(lemmy_BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[lemmy_BOW]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=3, id2word=dictionary, passes=2, workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Word: 0.035*\"blablacar\" + 0.034*\"rides\" + 0.034*\"ticketing\" + 0.034*\"activity\" + 0.034*\"known\" + 0.033*\"distance\" + 0.033*\"markets\" + 0.033*\"offering\" + 0.033*\"sharing\" + 0.033*\"diversified\"\n",
      "Topic: 1 \n",
      "Word: 0.036*\"marketplace\" + 0.033*\"country\" + 0.033*\"highway\" + 0.033*\"platform\" + 0.033*\"list\" + 0.033*\"acquired\" + 0.033*\"november\" + 0.032*\"plan\" + 0.032*\"travel\" + 0.032*\"driving\"\n",
      "Topic: 2 \n",
      "Word: 0.047*\"called\" + 0.047*\"blablabus\" + 0.040*\"city\" + 0.040*\"book\" + 0.040*\"going\" + 0.040*\"seat\" + 0.034*\"startup\" + 0.034*\"revenue\" + 0.034*\"percent\" + 0.034*\"compared\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} \\nWord: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(lemmy_BOW, minimum_probability=0.2, num_topics=5, id2word=dictionary, passes=3, workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.095*\"blablacar\" + 0.052*\"ride\" + 0.052*\"diversified\" + 0.052*\"offering\" + 0.052*\"markets\" + 0.052*\"difference\" + 0.052*\"long\" + 0.052*\"sharing\" + 0.052*\"known\" + 0.052*\"distance\"\n",
      "Topic: 1 \n",
      "Words: 0.087*\"marketplace\" + 0.048*\"ouibus\" + 0.048*\"ride\" + 0.048*\"company\" + 0.048*\"tolls\" + 0.048*\"november\" + 0.048*\"highway\" + 0.048*\"passengers\" + 0.048*\"acquired\" + 0.048*\"road\"\n",
      "Topic: 2 \n",
      "Words: 0.091*\"book\" + 0.091*\"ride\" + 0.091*\"seat\" + 0.091*\"city\" + 0.091*\"going\" + 0.015*\"blablabus\" + 0.015*\"ouibus\" + 0.015*\"called\" + 0.015*\"marketplace\" + 0.015*\"blablacar\"\n",
      "Topic: 3 \n",
      "Words: 0.024*\"ride\" + 0.024*\"called\" + 0.024*\"blablabus\" + 0.024*\"ouibus\" + 0.024*\"blablacar\" + 0.024*\"going\" + 0.024*\"city\" + 0.024*\"company\" + 0.024*\"seat\" + 0.024*\"marketplace\"\n",
      "Topic: 4 \n",
      "Words: 0.059*\"startup\" + 0.059*\"announced\" + 0.059*\"revenue\" + 0.059*\"french\" + 0.059*\"grew\" + 0.059*\"compared\" + 0.059*\"company\" + 0.059*\"percent\" + 0.059*\"blablabus\" + 0.059*\"called\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
